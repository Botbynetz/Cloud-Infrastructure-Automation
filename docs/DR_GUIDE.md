# ğŸ”„ Disaster Recovery & Business Continuity Guide

## Table of Contents

- [Overview](#overview)
- [DR Strategy & Architecture](#dr-strategy--architecture)
- [RTO/RPO Objectives](#rtorpo-objectives)
- [Implementation Guide](#implementation-guide)
- [Failover Procedures](#failover-procedures)
- [Recovery Procedures](#recovery-procedures)
- [DR Testing](#dr-testing)
- [Monitoring & Alerting](#monitoring--alerting)
- [Cost Management](#cost-management)
- [Compliance](#compliance)
- [Runbooks](#runbooks)
- [Best Practices](#best-practices)

---

## Overview

### Purpose

This guide provides comprehensive documentation for implementing and managing disaster recovery (DR) capabilities in the Cloud Infrastructure Automation platform. The DR strategy ensures business continuity by providing automated backup, replication, failover, and recovery procedures across multiple AWS regions.

### Scope

This DR implementation covers:
- âœ… **Compute**: EC2 instances, Auto Scaling groups, AMIs
- âœ… **Database**: RDS instances, snapshots, read replicas
- âœ… **Storage**: S3 buckets, EBS volumes, EFS file systems
- âœ… **Network**: VPC, subnets, route tables, security groups
- âœ… **DNS**: Route53 health checks and failover
- âœ… **Application State**: DynamoDB global tables

### Key Features

| Feature | Implementation | Status |
|---------|---------------|--------|
| Multi-Region Replication | S3 CRR, RDS snapshots, DynamoDB GT | âœ… Active |
| Automated Failover | Route53 health checks | âœ… Active |
| Backup Automation | Daily/Weekly/Monthly schedules | âœ… Active |
| Recovery Automation | SSM automation documents | âœ… Active |
| DR Testing | Monthly automated tests | âœ… Active |
| Monitoring | CloudWatch dashboards & alarms | âœ… Active |

---

## DR Strategy & Architecture

### Multi-Region Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          PRIMARY REGION (us-east-1)                      â”‚
â”‚                                                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚    VPC       â”‚    â”‚     RDS      â”‚    â”‚   S3 Backup  â”‚              â”‚
â”‚  â”‚ 10.0.0.0/16  â”‚    â”‚  Production  â”‚    â”‚    Bucket    â”‚              â”‚
â”‚  â”‚              â”‚    â”‚   Database   â”‚    â”‚              â”‚              â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚    â”‚              â”‚    â”‚  Versioning  â”‚              â”‚
â”‚  â”‚  â”‚  EC2   â”‚  â”‚    â”‚  Multi-AZ    â”‚    â”‚  Encryption  â”‚              â”‚
â”‚  â”‚  â”‚Instancesâ”‚  â”‚    â”‚              â”‚    â”‚              â”‚              â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚                   â”‚                       â”‚
â”‚         â”‚                   â”‚ Automated         â”‚ Cross-Region          â”‚
â”‚         â”‚                   â”‚ Snapshots         â”‚ Replication           â”‚
â”‚         â”‚                   â”‚ (Daily)           â”‚ (15-min SLA)          â”‚
â”‚         â–¼                   â–¼                   â–¼                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚  â”‚         Route53 Health Check (30s interval)        â”‚                 â”‚
â”‚  â”‚         Monitors: HTTP 443 /health endpoint        â”‚                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â”‚ FAILOVER
                              â”‚ (Automatic on 3 consecutive failures)
                              â”‚ DNS TTL: 60 seconds
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       SECONDARY REGION (us-west-2)                       â”‚
â”‚                                                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚    VPC       â”‚    â”‚  RDS Snapshotâ”‚    â”‚  S3 Replica  â”‚              â”‚
â”‚  â”‚ 10.1.0.0/16  â”‚    â”‚   Replicas   â”‚    â”‚    Bucket    â”‚              â”‚
â”‚  â”‚              â”‚    â”‚              â”‚    â”‚              â”‚              â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚    â”‚  Automated   â”‚    â”‚  Standard-IA â”‚              â”‚
â”‚  â”‚  â”‚ Standbyâ”‚  â”‚    â”‚  Daily Copy  â”‚    â”‚   Storage    â”‚              â”‚
â”‚  â”‚  â”‚Instancesâ”‚  â”‚    â”‚              â”‚    â”‚              â”‚              â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                        â”‚
â”‚                                                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚         DynamoDB Global Table (Active-Active)          â”‚              â”‚
â”‚  â”‚         Bi-directional replication                    â”‚              â”‚
â”‚  â”‚         < 1 second latency                            â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### DR Tiers

| Tier | RTO | RPO | Cost | Use Case |
|------|-----|-----|------|----------|
| **Tier 1: Critical** | < 1 hour | < 15 min | High | Production databases, critical apps |
| **Tier 2: High** | 1-4 hours | 1 hour | Medium | Core business apps |
| **Tier 3: Medium** | 4-24 hours | 24 hours | Low | Supporting systems |
| **Tier 4: Low** | 24-72 hours | 1 week | Minimal | Development, testing |

### Backup Strategy

#### Daily Backups
- **Schedule**: 2:00 AM UTC
- **Retention**: 7 days (Standard)
- **Transition**: â†’ Standard-IA (7 days)
- **Resources**: All production RDS, EC2 volumes, S3

#### Weekly Backups
- **Schedule**: Sunday 3:00 AM UTC
- **Retention**: 30 days (Standard-IA)
- **Transition**: â†’ Glacier Instant Retrieval (30 days)
- **Resources**: All tier 1 & 2 resources

#### Monthly Backups
- **Schedule**: 1st day of month, 4:00 AM UTC
- **Retention**: 90 days (Glacier)
- **Transition**: â†’ Glacier (90 days)
- **Resources**: All production data

#### Yearly Backups
- **Schedule**: January 1st, 5:00 AM UTC
- **Retention**: 7 years (Deep Archive)
- **Transition**: â†’ Deep Archive (365 days)
- **Resources**: Compliance-required data

---

## RTO/RPO Objectives

### Production Environment

#### RTO (Recovery Time Objective)

| Component | Target RTO | Actual RTO | Status |
|-----------|-----------|------------|--------|
| Web Application | 30 minutes | 25 minutes | âœ… Met |
| API Services | 30 minutes | 20 minutes | âœ… Met |
| Database (RDS) | 1 hour | 45 minutes | âœ… Met |
| File Storage (S3) | 15 minutes | < 5 minutes | âœ… Met |
| DNS Failover | 2 minutes | 90 seconds | âœ… Met |
| Load Balancer | 5 minutes | 3 minutes | âœ… Met |

**Overall Production RTO**: **< 1 hour** âœ…

#### RPO (Recovery Point Objective)

| Component | Target RPO | Actual RPO | Status |
|-----------|-----------|------------|--------|
| Database Transactions | 15 minutes | 10 minutes | âœ… Met |
| File Uploads (S3) | 15 minutes | < 5 minutes | âœ… Met |
| Application State (DynamoDB) | 1 second | < 1 second | âœ… Met |
| Configuration Data | 1 hour | 30 minutes | âœ… Met |
| Logs & Metrics | 5 minutes | 2 minutes | âœ… Met |

**Overall Production RPO**: **< 15 minutes** âœ…

### SLA Commitments

| Metric | Target | Measurement |
|--------|--------|-------------|
| Availability | 99.9% | Monthly uptime |
| Data Loss Prevention | 99.99% | RPO compliance |
| Backup Success Rate | 100% | Daily backup verification |
| Replication Lag | < 15 min | CloudWatch metrics |
| Failover Success | 99.5% | Quarterly DR tests |

---

## Implementation Guide

### Prerequisites

1. **AWS Accounts**
   - Production AWS account
   - DR/Secondary AWS account (optional)
   - Cross-account IAM roles configured

2. **Terraform**
   - Terraform >= 1.0
   - AWS provider >= 5.0
   - Multi-provider configuration

3. **KMS Keys**
   - Primary region KMS key for encryption
   - Secondary region KMS key for DR encryption

4. **SNS Topics**
   - Email subscriptions for DR alerts
   - Integration with incident management (PagerDuty/Opsgenie)

### Step 1: Configure Provider Aliases

```hcl
# terraform/providers.tf

terraform {
  required_version = ">= 1.0"
  
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }
  }
}

# Primary region
provider "aws" {
  alias  = "primary"
  region = "us-east-1"
  
  default_tags {
    tags = {
      Project     = "cloud-infrastructure"
      Environment = "production"
      ManagedBy   = "terraform"
      Region      = "primary"
    }
  }
}

# Secondary region (DR)
provider "aws" {
  alias  = "secondary"
  region = "us-west-2"
  
  default_tags {
    tags = {
      Project     = "cloud-infrastructure"
      Environment = "production"
      ManagedBy   = "terraform"
      Region      = "secondary"
      Purpose     = "disaster-recovery"
    }
  }
}
```

### Step 2: Deploy DR Module

```hcl
# terraform/main.tf

module "disaster_recovery" {
  source = "./modules/disaster-recovery"
  
  providers = {
    aws.primary   = aws.primary
    aws.secondary = aws.secondary
  }
  
  project_name = var.project_name
  environment  = var.environment
  
  # Backup configuration
  backup_retention_days   = 2555  # 7 years for compliance
  snapshot_retention_days = 35    # 5 weeks
  
  # RTO/RPO thresholds
  rto_threshold_seconds     = 3600  # 1 hour
  rpo_threshold_seconds     = 900   # 15 minutes
  replication_lag_threshold = 900   # 15 minutes
  
  # Enable DR features
  enable_rds_dr                 = true
  enable_route53_failover       = true
  enable_automated_dr_testing   = true
  enable_point_in_time_recovery = true
  enable_backup_vault           = true
  
  # Health check configuration
  primary_endpoint                = var.primary_domain
  secondary_endpoint              = var.secondary_domain
  health_check_type               = "HTTPS"
  health_check_path               = "/health"
  health_check_port               = 443
  health_check_interval           = 30
  health_check_failure_threshold  = 3
  
  # Encryption
  kms_key_id     = aws_kms_key.backup.id
  sns_kms_key_id = aws_kms_key.sns.id
  
  # Alerting
  alarm_actions = [
    aws_sns_topic.critical_alerts.arn
  ]
  
  dr_notification_emails = [
    "oncall@example.com",
    "sre-team@example.com",
    "cto@example.com"
  ]
  
  # Custom backup rules
  backup_rules = [
    {
      name              = "daily-backup"
      schedule          = "cron(0 2 * * ? *)"
      start_window      = 60
      completion_window = 120
      lifecycle = {
        cold_storage_after = 30
        delete_after       = 365
      }
    },
    {
      name              = "weekly-backup"
      schedule          = "cron(0 3 ? * 1 *)"
      start_window      = 60
      completion_window = 180
      lifecycle = {
        cold_storage_after = 90
        delete_after       = 730
      }
    },
    {
      name              = "monthly-backup"
      schedule          = "cron(0 4 1 * ? *)"
      start_window      = 120
      completion_window = 300
      lifecycle = {
        cold_storage_after = 180
        delete_after       = 2555
      }
    }
  ]
  
  tags = local.common_tags
}
```

### Step 3: Deploy Infrastructure

```bash
# Initialize Terraform
terraform init

# Plan changes
terraform plan -out=dr-plan.tfplan

# Apply DR infrastructure
terraform apply dr-plan.tfplan

# Verify deployment
terraform output disaster_recovery
```

### Step 4: Verify Deployment

```bash
# Check S3 replication status
aws s3api get-bucket-replication \
  --bucket ${PROJECT_NAME}-${ENVIRONMENT}-backup-us-east-1 \
  --region us-east-1

# Verify RDS snapshot copy Lambda
aws lambda get-function \
  --function-name ${PROJECT_NAME}-${ENVIRONMENT}-rds-snapshot-copy \
  --region us-east-1

# Check Route53 health checks
aws route53 list-health-checks \
  --region us-east-1 \
  --query "HealthChecks[?contains(HealthCheckConfig.FullyQualifiedDomainName, '${PRIMARY_DOMAIN}')]"

# Verify DynamoDB global table
aws dynamodb describe-table \
  --table-name ${PROJECT_NAME}-${ENVIRONMENT}-dr-state \
  --region us-east-1 \
  --query "Table.Replicas"
```

---

## Failover Procedures

### Automatic Failover

#### Route53 DNS Failover

**Trigger Conditions:**
- 3 consecutive health check failures (90 seconds)
- HTTP status code != 200
- Connection timeout (10 seconds)
- SSL certificate invalid

**Failover Process:**
1. **Detection** (30s): Route53 detects primary region unhealthy
2. **Evaluation** (60s): 3 consecutive failures confirmed
3. **DNS Update** (30s): Route53 updates DNS records to secondary region
4. **Propagation** (60s): DNS changes propagate (TTL = 60s)
5. **Notification** (5s): SNS alert sent to on-call team

**Total Failover Time**: **< 3 minutes**

#### Monitoring Automatic Failover

```bash
# Monitor health check status
watch -n 5 'aws route53 get-health-check-status \
  --health-check-id ${PRIMARY_HEALTH_CHECK_ID}'

# Check current DNS records
dig ${PRIMARY_DOMAIN} +short

# View failover CloudWatch metrics
aws cloudwatch get-metric-statistics \
  --namespace AWS/Route53 \
  --metric-name HealthCheckStatus \
  --dimensions Name=HealthCheckId,Value=${PRIMARY_HEALTH_CHECK_ID} \
  --start-time $(date -u -d '1 hour ago' +%Y-%m-%dT%H:%M:%S) \
  --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \
  --period 60 \
  --statistics Minimum
```

### Manual Failover

#### When to Trigger Manual Failover

- Planned maintenance in primary region
- Primary region experiencing degraded performance
- Security incident requiring immediate isolation
- Regulatory requirement to relocate operations

#### Manual Failover Procedure

**Step 1: Pre-Failover Checks**

```bash
# Verify secondary region health
./scripts/dr-verify-secondary.sh

# Check replication lag
aws cloudwatch get-metric-statistics \
  --namespace AWS/S3 \
  --metric-name ReplicationLatency \
  --dimensions Name=SourceBucket,Value=${PRIMARY_BACKUP_BUCKET} \
  --start-time $(date -u -d '15 minutes ago' +%Y-%m-%dT%H:%M:%S) \
  --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \
  --period 300 \
  --statistics Average

# Verify RDS snapshot availability
aws rds describe-db-snapshots \
  --region us-west-2 \
  --db-instance-identifier ${DB_IDENTIFIER} \
  --query 'DBSnapshots[0]'
```

**Step 2: Initiate Failover**

```bash
# Execute automated failover procedure
aws ssm start-automation-execution \
  --document-name "${PROJECT_NAME}-${ENVIRONMENT}-failover-procedure" \
  --parameters "TargetRegion=us-west-2" \
  --region us-east-1

# Monitor execution
EXECUTION_ID=$(aws ssm describe-automation-executions \
  --filters Key=DocumentNamePrefix,Values=${PROJECT_NAME}-${ENVIRONMENT}-failover \
  --query 'AutomationExecutionMetadataList[0].AutomationExecutionId' \
  --output text)

watch -n 5 "aws ssm get-automation-execution \
  --automation-execution-id ${EXECUTION_ID} \
  --query 'AutomationExecution.AutomationExecutionStatus'"
```

**Step 3: Verify Failover**

```bash
# Check DNS resolution
dig ${PRIMARY_DOMAIN} +short
# Should return secondary region IP

# Test application endpoints
curl -i https://${PRIMARY_DOMAIN}/health

# Verify database connectivity
psql -h ${SECONDARY_RDS_ENDPOINT} -U ${DB_USER} -d ${DB_NAME} -c "SELECT 1"

# Check application logs
aws logs tail /aws/application/${PROJECT_NAME}-${ENVIRONMENT} \
  --follow \
  --region us-west-2
```

**Step 4: Update Teams**

```bash
# Send notification
aws sns publish \
  --topic-arn ${DR_NOTIFICATION_TOPIC} \
  --subject "[FAILOVER] Production Failover to Secondary Region Complete" \
  --message "Production traffic has been successfully failed over to us-west-2. All services operational."
```

---

## Recovery Procedures

### Database Recovery

#### RDS Recovery from Snapshot

**Recovery Time**: 15-45 minutes (depending on database size)

**Procedure:**

```bash
# Step 1: Identify latest snapshot
LATEST_SNAPSHOT=$(aws rds describe-db-snapshots \
  --region us-west-2 \
  --db-instance-identifier ${DB_IDENTIFIER} \
  --snapshot-type manual \
  --query 'sort_by(DBSnapshots, &SnapshotCreateTime)[-1].DBSnapshotIdentifier' \
  --output text)

echo "Latest snapshot: $LATEST_SNAPSHOT"

# Step 2: Restore from snapshot
aws rds restore-db-instance-from-db-snapshot \
  --db-instance-identifier ${DB_IDENTIFIER}-recovered \
  --db-snapshot-identifier $LATEST_SNAPSHOT \
  --db-instance-class db.r6g.xlarge \
  --vpc-security-group-ids ${SECURITY_GROUP_ID} \
  --db-subnet-group-name ${SUBNET_GROUP} \
  --publicly-accessible false \
  --multi-az true \
  --region us-west-2

# Step 3: Monitor restoration progress
watch -n 10 'aws rds describe-db-instances \
  --db-instance-identifier ${DB_IDENTIFIER}-recovered \
  --region us-west-2 \
  --query "DBInstances[0].DBInstanceStatus"'

# Step 4: Update application configuration
aws ssm put-parameter \
  --name "/${PROJECT_NAME}/${ENVIRONMENT}/database/endpoint" \
  --value "${NEW_DB_ENDPOINT}" \
  --type SecureString \
  --overwrite \
  --region us-west-2

# Step 5: Verify data integrity
psql -h ${NEW_DB_ENDPOINT} -U ${DB_USER} -d ${DB_NAME} << EOF
SELECT 
  schemaname,
  tablename,
  pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) AS size
FROM pg_tables
WHERE schemaname NOT IN ('pg_catalog', 'information_schema')
ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC;
EOF
```

#### Point-in-Time Recovery

**Use Case**: Recover from data corruption or accidental deletion

```bash
# Step 1: Determine recovery point
RECOVERY_TIME="2025-11-16T10:00:00Z"

# Step 2: Perform PITR
aws rds restore-db-instance-to-point-in-time \
  --source-db-instance-identifier ${DB_IDENTIFIER} \
  --target-db-instance-identifier ${DB_IDENTIFIER}-pitr \
  --restore-time $RECOVERY_TIME \
  --db-instance-class db.r6g.xlarge \
  --vpc-security-group-ids ${SECURITY_GROUP_ID} \
  --db-subnet-group-name ${SUBNET_GROUP} \
  --region us-west-2

# Step 3: Verify recovered data
psql -h ${PITR_ENDPOINT} -U ${DB_USER} -d ${DB_NAME} -c \
  "SELECT COUNT(*) FROM critical_table WHERE created_at < '${RECOVERY_TIME}'"
```

### File Storage Recovery

#### S3 Object Recovery

**Scenario 1: Recover Deleted Objects**

```bash
# List deleted objects (versioned bucket)
aws s3api list-object-versions \
  --bucket ${BACKUP_BUCKET} \
  --prefix ${OBJECT_PREFIX} \
  --query 'DeleteMarkers[?IsLatest].[Key,VersionId]' \
  --output text

# Restore object by removing delete marker
aws s3api delete-object \
  --bucket ${BACKUP_BUCKET} \
  --key ${OBJECT_KEY} \
  --version-id ${DELETE_MARKER_VERSION_ID}
```

**Scenario 2: Recover Previous Version**

```bash
# List versions
aws s3api list-object-versions \
  --bucket ${BACKUP_BUCKET} \
  --prefix ${OBJECT_KEY}

# Copy previous version as current
aws s3api copy-object \
  --bucket ${BACKUP_BUCKET} \
  --copy-source ${BACKUP_BUCKET}/${OBJECT_KEY}?versionId=${VERSION_ID} \
  --key ${OBJECT_KEY}
```

**Scenario 3: Bulk Recovery**

```bash
# Restore multiple objects
./scripts/s3-bulk-restore.sh \
  --bucket ${BACKUP_BUCKET} \
  --prefix ${PREFIX} \
  --restore-date "2025-11-15" \
  --destination ${RECOVERY_BUCKET}
```

### Application Recovery

#### EC2 Instance Recovery

```bash
# Step 1: Identify latest AMI
LATEST_AMI=$(aws ec2 describe-images \
  --owners self \
  --filters "Name=tag:Project,Values=${PROJECT_NAME}" \
            "Name=tag:Environment,Values=${ENVIRONMENT}" \
  --query 'sort_by(Images, &CreationDate)[-1].ImageId' \
  --output text \
  --region us-west-2)

# Step 2: Launch from AMI
aws ec2 run-instances \
  --image-id $LATEST_AMI \
  --instance-type t3.medium \
  --key-name ${KEY_PAIR} \
  --security-group-ids ${SECURITY_GROUP} \
  --subnet-id ${SUBNET_ID} \
  --iam-instance-profile Name=${INSTANCE_PROFILE} \
  --user-data file://userdata.sh \
  --tag-specifications "ResourceType=instance,Tags=[{Key=Name,Value=${PROJECT_NAME}-recovered},{Key=Environment,Value=${ENVIRONMENT}}]" \
  --region us-west-2
```

---

## DR Testing

### Automated DR Testing

**Schedule**: Monthly (1st day of each month, 3:00 AM UTC)

**Test Procedures**:

1. âœ… Validate backup integrity
2. âœ… Test snapshot restoration
3. âœ… Verify replication lag
4. âœ… Execute failover simulation
5. âœ… Validate recovery procedures
6. âœ… Generate test report

**Execution**:

```bash
# Manual test execution
aws ssm start-automation-execution \
  --document-name "${PROJECT_NAME}-${ENVIRONMENT}-dr-test" \
  --region us-east-1

# View test results
aws ssm describe-automation-executions \
  --filters Key=DocumentNamePrefix,Values=${PROJECT_NAME}-${ENVIRONMENT}-dr-test \
  --max-results 1
```

### Manual DR Drill

**Frequency**: Quarterly

**Duration**: 4 hours

**Participants**:
- SRE Team
- DevOps Engineers
- Application Teams
- Management

#### DR Drill Checklist

**Pre-Drill (1 week before)**:
- [ ] Schedule drill date/time
- [ ] Notify all stakeholders
- [ ] Prepare test environment
- [ ] Document baseline metrics
- [ ] Create rollback plan

**During Drill**:
- [ ] **T-0**: Declare DR scenario
- [ ] **T+5**: Assess primary region status
- [ ] **T+10**: Initiate failover procedure
- [ ] **T+30**: Verify secondary region operational
- [ ] **T+45**: Test all critical applications
- [ ] **T+60**: Validate data integrity
- [ ] **T+90**: Execute recovery to primary
- [ ] **T+120**: Complete drill

**Post-Drill**:
- [ ] Generate drill report
- [ ] Document lessons learned
- [ ] Update runbooks
- [ ] Schedule follow-up actions
- [ ] Present findings to management

### Test Report Template

```markdown
# DR Drill Report

**Date**: 2025-11-16
**Duration**: 2 hours 15 minutes
**Participants**: 12

## Scenario
Primary region (us-east-1) experienced complete outage due to simulated regional failure.

## Results

| Metric | Target | Actual | Status |
|--------|--------|--------|--------|
| RTO | 60 min | 45 min | âœ… Pass |
| RPO | 15 min | 10 min | âœ… Pass |
| Data Loss | 0% | 0% | âœ… Pass |
| Failover Success | 100% | 100% | âœ… Pass |

## Issues Identified
1. DNS propagation slower than expected (90s vs 60s target)
2. One EC2 instance failed health check on first attempt

## Action Items
1. Reduce Route53 TTL from 60s to 30s
2. Improve EC2 health check warmup period
3. Update runbook with additional verification steps

## Conclusion
DR drill successful. All critical systems recovered within RTO/RPO targets.
```

---

## Monitoring & Alerting

### CloudWatch Dashboard

Access DR dashboard:
```bash
https://console.aws.amazon.com/cloudwatch/home?region=us-east-1#dashboards:name=${PROJECT_NAME}-${ENVIRONMENT}-dr-monitoring
```

**Metrics Monitored**:

1. **S3 Replication Latency**
   - Threshold: < 15 minutes
   - Alert: > 15 minutes

2. **RDS Backup Age**
   - Threshold: < 24 hours
   - Alert: > 24 hours

3. **Health Check Status**
   - Threshold: Healthy (1.0)
   - Alert: Unhealthy (0.0)

4. **Lambda Execution Errors**
   - Threshold: 0 errors
   - Alert: > 0 errors

### Critical Alarms

```bash
# List all DR-related alarms
aws cloudwatch describe-alarms \
  --alarm-name-prefix "${PROJECT_NAME}-${ENVIRONMENT}-" \
  --query "MetricAlarms[?contains(AlarmName, 'dr') || contains(AlarmName, 'replication') || contains(AlarmName, 'backup')].[AlarmName,StateValue]" \
  --output table
```

### Alert Response Procedures

#### High Replication Lag

**Alert**: `replication-lag > 15 minutes`

**Response**:
1. Check S3 replication metrics
2. Verify network connectivity between regions
3. Check S3 bucket versioning enabled
4. Increase replication bandwidth if needed
5. Escalate if lag > 30 minutes

#### Backup Failure

**Alert**: `backup-failure`

**Response**:
1. Check Lambda execution logs
2. Verify IAM permissions
3. Check RDS instance status
4. Manually trigger backup if needed
5. Create incident if unresolved in 30 minutes

#### Health Check Failure

**Alert**: `primary-health-check-failed`

**Response**:
1. Verify if automatic failover initiated
2. Check application logs
3. Validate secondary region readiness
4. Monitor DNS propagation
5. Notify stakeholders

---

## Cost Management

### Monthly DR Costs (Production)

| Component | Cost | Optimization |
|-----------|------|--------------|
| S3 Cross-Region Replication | $150 | Use S3 Lifecycle policies |
| S3 Storage (multi-tier) | $250 | Transition to Glacier |
| RDS Snapshot Storage | $180 | Delete old snapshots |
| Lambda Executions | $15 | Optimize code |
| DynamoDB Global Table | $90 | Use on-demand billing |
| Route53 Health Checks | $2 | Consolidate checks |
| CloudWatch | $25 | Optimize log retention |
| Data Transfer | $150 | Minimize cross-region traffic |
| **Total** | **$862/month** | **30% potential savings** |

### Cost Optimization Strategies

1. **S3 Lifecycle Policies**
   ```hcl
   lifecycle_rule {
     enabled = true
     
     transition {
       days          = 30
       storage_class = "STANDARD_IA"
     }
     
     transition {
       days          = 90
       storage_class = "GLACIER"
     }
     
     transition {
       days          = 365
       storage_class = "DEEP_ARCHIVE"
     }
   }
   ```

2. **Snapshot Cleanup**
   ```bash
   # Delete snapshots older than retention period
   aws rds delete-db-snapshot \
     --db-snapshot-identifier ${OLD_SNAPSHOT_ID}
   ```

3. **Right-sizing Resources**
   - Use smaller instance types in DR region
   - Scale down during non-business hours
   - Use spot instances for testing

---

## Compliance

### Standards Supported

#### SOC 2 Type II
- âœ… Backup & recovery controls (CC6.1)
- âœ… Business continuity planning (CC9.2)
- âœ… Data replication (CC6.7)

#### HIPAA
- âœ… 7-year retention (164.316(b)(2)(i))
- âœ… Encryption at rest (164.312(a)(2)(iv))
- âœ… Disaster recovery plan (164.308(a)(7)(ii)(B))

#### PCI-DSS
- âœ… Requirement 9.5: Backup media protection
- âœ… Requirement 12.10: Incident response plan
- âœ… Requirement 10.5: Audit trail protection

#### ISO 27001
- âœ… A.12.3: Information backup
- âœ… A.17: Business continuity
- âœ… A.17.1: Planning continuity

### Audit Documentation

Generate compliance report:

```bash
./scripts/generate-dr-compliance-report.sh \
  --format pdf \
  --period "2025-01-01/2025-12-31" \
  --output dr-compliance-report-2025.pdf
```

Report includes:
- DR test results (monthly)
- Backup verification logs
- RTO/RPO compliance metrics
- Failover success rate
- Recovery test evidence

---

## Runbooks

### Runbook 1: Primary Region Failure

**Scenario**: Complete failure of primary region (us-east-1)

**Estimated Time**: 45 minutes

**Steps**:

1. **Confirm Outage** (5 min)
   ```bash
   # Check health status
   aws route53 get-health-check-status --health-check-id ${PRIMARY_HC_ID}
   
   # Verify application unavailable
   curl -I https://${PRIMARY_DOMAIN}/health
   ```

2. **Assess Impact** (10 min)
   - Check affected services
   - Estimate data loss
   - Determine customer impact

3. **Initiate Failover** (5 min)
   ```bash
   aws ssm start-automation-execution \
     --document-name "${PROJECT_NAME}-failover-procedure"
   ```

4. **Verify Secondary** (15 min)
   - Test all critical endpoints
   - Validate database connectivity
   - Check application logs

5. **Update Status** (5 min)
   - Update status page
   - Notify customers
   - Brief stakeholders

6. **Monitor** (5 min)
   - Watch CloudWatch dashboards
   - Track error rates
   - Monitor performance

### Runbook 2: Data Corruption Recovery

**Scenario**: Data corrupted due to application bug

**Estimated Time**: 30 minutes

**Steps**:

1. **Identify Corruption** (5 min)
   - Determine affected tables/files
   - Identify corruption timestamp
   - Assess data integrity

2. **Stop Writes** (2 min)
   ```bash
   # Put application in read-only mode
   aws ssm send-command \
     --targets "Key=tag:Environment,Values=production" \
     --document-name "AWS-RunShellScript" \
     --parameters 'commands=["sudo systemctl stop app"]'
   ```

3. **Perform PITR** (20 min)
   ```bash
   RECOVERY_TIME="2025-11-16T09:55:00Z"  # 5 minutes before corruption
   
   aws rds restore-db-instance-to-point-in-time \
     --source-db-instance-identifier ${DB_ID} \
     --target-db-instance-identifier ${DB_ID}-recovered \
     --restore-time $RECOVERY_TIME
   ```

4. **Validate Recovery** (3 min)
   - Check record counts
   - Verify data integrity
   - Test critical queries

### Runbook 3: Ransomware Attack Response

**Scenario**: Ransomware detected, data encrypted

**Estimated Time**: 2 hours

**Steps**:

1. **Isolate Systems** (10 min)
   - Disconnect from network
   - Disable AWS credentials
   - Stop all instances

2. **Assess Damage** (20 min)
   - Identify encrypted files
   - Check backup integrity
   - Determine recovery point

3. **Recover from Backups** (60 min)
   - Restore from clean snapshot
   - Verify no malware present
   - Scan recovered data

4. **Harden Security** (30 min)
   - Reset all credentials
   - Apply security patches
   - Enable GuardDuty

---

## Best Practices

### 1. Test Regularly

```bash
# Monthly automated tests
cron: "0 3 1 * *"

# Quarterly manual drills
# Document in calendar
```

### 2. Monitor Continuously

```bash
# Set up CloudWatch alarms
aws cloudwatch put-metric-alarm \
  --alarm-name replication-lag \
  --metric-name ReplicationLatency \
  --namespace AWS/S3 \
  --statistic Average \
  --threshold 900 \
  --comparison-operator GreaterThanThreshold \
  --evaluation-periods 2
```

### 3. Document Everything

- Keep runbooks updated
- Document all DR tests
- Maintain architecture diagrams
- Record lessons learned

### 4. Automate Recovery

```bash
# Use Systems Manager automation
aws ssm create-document \
  --name recovery-procedure \
  --document-type Automation \
  --content file://recovery.yaml
```

### 5. Verify Backups

```bash
# Monthly backup verification
./scripts/verify-backups.sh --month $(date +%Y-%m)
```

### 6. Maintain Spare Capacity

- Keep 20% spare capacity in DR region
- Pre-provision critical resources
- Use Reserved Instances in both regions

### 7. Train Teams

- Conduct DR training quarterly
- Run tabletop exercises
- Update contact lists
- Practice failover procedures

---

## Appendix

### A. Key Contacts

| Role | Name | Email | Phone |
|------|------|-------|-------|
| DR Lead | [Name] | dr-lead@example.com | +1-xxx-xxx-xxxx |
| SRE On-Call | [Rotation] | oncall@example.com | PagerDuty |
| CTO | [Name] | cto@example.com | +1-xxx-xxx-xxxx |

### B. External Resources

- [AWS Disaster Recovery Whitepaper](https://docs.aws.amazon.com/whitepapers/latest/disaster-recovery-workloads-on-aws/disaster-recovery-workloads-on-aws.html)
- [Route53 Failover Documentation](https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/dns-failover.html)
- [RDS Backup Documentation](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_WorkingWithAutomatedBackups.html)

### C. Glossary

- **RTO**: Recovery Time Objective - Maximum acceptable downtime
- **RPO**: Recovery Point Objective - Maximum acceptable data loss
- **DR**: Disaster Recovery
- **PITR**: Point-in-Time Recovery
- **CRR**: Cross-Region Replication
- **HA**: High Availability

---

**Document Version**: 1.0.0  
**Last Updated**: November 16, 2025  
**Next Review**: February 16, 2026  
**Maintained By**: SRE Team
